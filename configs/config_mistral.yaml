# configs/config_mistral.yaml
model:
  name: "mistralai/Mistral-7B-Instruct-v0.2"   # hoặc bản nhỏ hơn nếu có
  max_length: 4096
  gradient_checkpointing: true

lora:
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules: ["q_proj","k_proj","v_proj","o_proj","gate_proj","up_proj","down_proj"]

training:
  output_dir: "experiments/checkpoints/mistral_lora"
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 8
  num_train_epochs: 3
  learning_rate: 2e-4
  weight_decay: 0.01
  warmup_ratio: 0.03
  logging_steps: 50
  save_steps: 500
  evaluation_strategy: "steps"
  eval_steps: 500
  fp16: true
  lr_scheduler_type: "cosine"
  max_grad_norm: 1.0

data:
  train_path: "data/processed/train_subset.jsonl"
  val_path: "data/processed/val_subset.jsonl"
  prompt_template: "### Task: Summarize the following scientific article into a concise abstract.\n\n### Article:\n{article}\n\n### Summary:"
  input_field: "article_text"     # hoặc "sections"
  target_field: "abstract_text"
  max_input_sentences: 60         # cắt bớt cho fits vào context
  max_target_sentences: 10
